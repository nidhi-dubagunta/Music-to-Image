{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('spotify_and_clean_lyrics.csv')\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lastfm_url', 'track', 'artist', 'seeds', 'number_of_emotion_tags',\n",
       "       'valence_tags', 'arousal_tags', 'dominance_tags', 'mbid', 'spotify_id',\n",
       "       'genre', 'seeds_encoded', 'lyrics', 'number_of_emotion_tags.1',\n",
       "       'genre.1', 'dominance_tags.1', 'arousal_tags.1', 'valence_tags.1',\n",
       "       'seeds.1', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
       "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'duration_ms', 'time_signature', 'processed_lyrics',\n",
       "       'clean_lyrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print nans in df['clean_lyrics']\n",
    "df[df['processed_lyrics'].isnull()]\n",
    "#remove the rows with nans in df['clean_lyrics']\n",
    "df = df[df['processed_lyrics'].notnull()]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>...</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>processed_lyrics</th>\n",
       "      <th>clean_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>Till I Collapse</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>6</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>5.273125</td>\n",
       "      <td>5.690625</td>\n",
       "      <td>cab93def-26c5-4fb0-bedd-26ec4c1619e1</td>\n",
       "      <td>4xkOaSrkexMciUUogZKVTS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.06220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>171.447</td>\n",
       "      <td>297787</td>\n",
       "      <td>4</td>\n",
       "      <td>sometimes feel tire yo leave yo leave feel wea...</td>\n",
       "      <td>sometimes feel tire yo leave yo leave feel wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.last.fm/music/metallica/_/st.%2banger</td>\n",
       "      <td>St Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>727a2529-7ee8-4860-aef6-7959884895cb</td>\n",
       "      <td>3fOc9x06lKJBhz435mInlH</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.4980</td>\n",
       "      <td>185.252</td>\n",
       "      <td>441133</td>\n",
       "      <td>4</td>\n",
       "      <td>st anger round neck st anger round neck never ...</td>\n",
       "      <td>st anger round neck st anger round neck never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.last.fm/music/rick%2bross/_/speedi...</td>\n",
       "      <td>Speedin</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Y96xd4Ce0J47dcalLrEC8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>100.059</td>\n",
       "      <td>204960</td>\n",
       "      <td>4</td>\n",
       "      <td>rick ross legendary runner know verse rick ros...</td>\n",
       "      <td>rick ross legendary runner know verse rick ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.last.fm/music/m.i.a./_/bamboo%2bbanga</td>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>MIA</td>\n",
       "      <td>['aggressive', 'fun', 'sexy', 'energetic']</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>99dd2c8c-e7c1-413e-8ea4-4497a00ffa18</td>\n",
       "      <td>6tqFC1DIOphJkCwrjVzPmg</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2120</td>\n",
       "      <td>0.04930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>125.984</td>\n",
       "      <td>298360</td>\n",
       "      <td>4</td>\n",
       "      <td>road runner road runner go hundred mile per ho...</td>\n",
       "      <td>road runner road runner go hundred mile per ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.last.fm/music/dope/_/die%2bmf%2bdie</td>\n",
       "      <td>Die MF Die</td>\n",
       "      <td>Dope</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>7</td>\n",
       "      <td>3.771176</td>\n",
       "      <td>5.348235</td>\n",
       "      <td>5.441765</td>\n",
       "      <td>b9eb3484-5e0e-4690-ab5a-ca91937032a5</td>\n",
       "      <td>5bU4KX47KqtDKKaLM4QCzh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.00169</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>126.020</td>\n",
       "      <td>186067</td>\n",
       "      <td>4</td>\n",
       "      <td>need forgiveness need hate need acceptance nee...</td>\n",
       "      <td>need forgiveness need hate need acceptance nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38953</th>\n",
       "      <td>https://www.last.fm/music/elliott%2bbrood/_/ca...</td>\n",
       "      <td>Cadillac Dust</td>\n",
       "      <td>Elliott BROOD</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>8d12992a-84cf-4d3b-83fa-622584368349</td>\n",
       "      <td>6EqH6OTtC3KMxRsU2OGF9A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.54300</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>203.503</td>\n",
       "      <td>194493</td>\n",
       "      <td>4</td>\n",
       "      <td>give get go take nothing soul roll dust roll s...</td>\n",
       "      <td>give get go take nothing soul roll dust roll s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38954</th>\n",
       "      <td>https://www.last.fm/music/ef/_/misinform%2bthe...</td>\n",
       "      <td>Misinform the Uninformed</td>\n",
       "      <td>EF</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>98063b6c-5276-455b-b5d9-7159e67c521f</td>\n",
       "      <td>0RW7stKmmTXuvrAvwo3XEW</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>130.066</td>\n",
       "      <td>461480</td>\n",
       "      <td>4</td>\n",
       "      <td>verse say tear star apart show replace sky ver...</td>\n",
       "      <td>verse say tear star apart show replace sky ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38955</th>\n",
       "      <td>https://www.last.fm/music/quietdrive/_/secret</td>\n",
       "      <td>Secret</td>\n",
       "      <td>Quietdrive</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>909ba2e0-6076-4ad8-8be9-a335725de4ef</td>\n",
       "      <td>2bRIsZ92JRKlvQOZlyR9CO</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.03340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0734</td>\n",
       "      <td>167.996</td>\n",
       "      <td>258373</td>\n",
       "      <td>4</td>\n",
       "      <td>hey bride mine love find another would make lo...</td>\n",
       "      <td>hey bride mine love find another would make lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>https://www.last.fm/music/medications/_/the%2b...</td>\n",
       "      <td>The Last of the Rest Was the End</td>\n",
       "      <td>Medications</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>ffd10ae8-858a-4b5e-819e-64f1174bbd42</td>\n",
       "      <td>7o3Np7cho9cBCrNDokxzYC</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.00433</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>144.844</td>\n",
       "      <td>324000</td>\n",
       "      <td>3</td>\n",
       "      <td>desperate day solution sell price high exit st...</td>\n",
       "      <td>desperate day solution sell price high exit st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>https://www.last.fm/music/daniel%2blanois/_/lo...</td>\n",
       "      <td>Lovechild</td>\n",
       "      <td>Daniel Lanois</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>2</td>\n",
       "      <td>6.685000</td>\n",
       "      <td>4.405000</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c</td>\n",
       "      <td>4fVObxldDzxxRD6a5Eth9s</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.90100</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>79.476</td>\n",
       "      <td>516280</td>\n",
       "      <td>4</td>\n",
       "      <td>child child oh child child child tremble forev...</td>\n",
       "      <td>child child oh child child child tremble forev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38958 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lastfm_url  \\\n",
       "0                                                      .   \n",
       "1      https://www.last.fm/music/metallica/_/st.%2banger   \n",
       "2      https://www.last.fm/music/rick%2bross/_/speedi...   \n",
       "3      https://www.last.fm/music/m.i.a./_/bamboo%2bbanga   \n",
       "4        https://www.last.fm/music/dope/_/die%2bmf%2bdie   \n",
       "...                                                  ...   \n",
       "38953  https://www.last.fm/music/elliott%2bbrood/_/ca...   \n",
       "38954  https://www.last.fm/music/ef/_/misinform%2bthe...   \n",
       "38955      https://www.last.fm/music/quietdrive/_/secret   \n",
       "38956  https://www.last.fm/music/medications/_/the%2b...   \n",
       "38957  https://www.last.fm/music/daniel%2blanois/_/lo...   \n",
       "\n",
       "                                  track         artist  \\\n",
       "0                       Till I Collapse         Eminem   \n",
       "1                              St Anger      Metallica   \n",
       "2                               Speedin      Rick Ross   \n",
       "3                          Bamboo Banga            MIA   \n",
       "4                            Die MF Die           Dope   \n",
       "...                                 ...            ...   \n",
       "38953                     Cadillac Dust  Elliott BROOD   \n",
       "38954          Misinform the Uninformed             EF   \n",
       "38955                            Secret     Quietdrive   \n",
       "38956  The Last of the Rest Was the End    Medications   \n",
       "38957                         Lovechild  Daniel Lanois   \n",
       "\n",
       "                                            seeds  number_of_emotion_tags  \\\n",
       "0                                  ['aggressive']                       6   \n",
       "1                                  ['aggressive']                       8   \n",
       "2                                  ['aggressive']                       1   \n",
       "3      ['aggressive', 'fun', 'sexy', 'energetic']                      13   \n",
       "4                                  ['aggressive']                       7   \n",
       "...                                           ...                     ...   \n",
       "38953                             ['transparent']                       1   \n",
       "38954                             ['transparent']                       1   \n",
       "38955                             ['transparent']                       1   \n",
       "38956                             ['transparent']                       1   \n",
       "38957                             ['transparent']                       2   \n",
       "\n",
       "       valence_tags  arousal_tags  dominance_tags  \\\n",
       "0          4.550000      5.273125        5.690625   \n",
       "1          3.710000      5.833000        5.427250   \n",
       "2          3.080000      5.870000        5.490000   \n",
       "3          6.555071      5.537214        5.691357   \n",
       "4          3.771176      5.348235        5.441765   \n",
       "...             ...           ...             ...   \n",
       "38953      5.370000      3.450000        5.330000   \n",
       "38954      5.370000      3.450000        5.330000   \n",
       "38955      5.370000      3.450000        5.330000   \n",
       "38956      5.370000      3.450000        5.330000   \n",
       "38957      6.685000      4.405000        5.625000   \n",
       "\n",
       "                                       mbid              spotify_id  ...  \\\n",
       "0      cab93def-26c5-4fb0-bedd-26ec4c1619e1  4xkOaSrkexMciUUogZKVTS  ...   \n",
       "1      727a2529-7ee8-4860-aef6-7959884895cb  3fOc9x06lKJBhz435mInlH  ...   \n",
       "2                                       NaN  3Y96xd4Ce0J47dcalLrEC8  ...   \n",
       "3      99dd2c8c-e7c1-413e-8ea4-4497a00ffa18  6tqFC1DIOphJkCwrjVzPmg  ...   \n",
       "4      b9eb3484-5e0e-4690-ab5a-ca91937032a5  5bU4KX47KqtDKKaLM4QCzh  ...   \n",
       "...                                     ...                     ...  ...   \n",
       "38953  8d12992a-84cf-4d3b-83fa-622584368349  6EqH6OTtC3KMxRsU2OGF9A  ...   \n",
       "38954  98063b6c-5276-455b-b5d9-7159e67c521f  0RW7stKmmTXuvrAvwo3XEW  ...   \n",
       "38955  909ba2e0-6076-4ad8-8be9-a335725de4ef  2bRIsZ92JRKlvQOZlyR9CO  ...   \n",
       "38956  ffd10ae8-858a-4b5e-819e-64f1174bbd42  7o3Np7cho9cBCrNDokxzYC  ...   \n",
       "38957  16c3d394-c4d4-4dc2-bbf1-b2bef3ac861c  4fVObxldDzxxRD6a5Eth9s  ...   \n",
       "\n",
       "      speechiness acousticness instrumentalness  liveness valence    tempo  \\\n",
       "0          0.1860      0.06220         0.000000    0.0816  0.1000  171.447   \n",
       "1          0.0678      0.00131         0.022800    0.0953  0.4980  185.252   \n",
       "2          0.0429      0.10900         0.000000    0.2100  0.4780  100.059   \n",
       "3          0.2120      0.04930         0.000000    0.0691  0.7130  125.984   \n",
       "4          0.0700      0.00169         0.000997    0.1090  0.5670  126.020   \n",
       "...           ...          ...              ...       ...     ...      ...   \n",
       "38953      0.4210      0.54300         0.089100    0.3390  0.2240  203.503   \n",
       "38954      0.0447      0.00051         0.711000    0.1790  0.2110  130.066   \n",
       "38955      0.1560      0.03340         0.000000    0.1350  0.0734  167.996   \n",
       "38956      0.0674      0.00433         0.072200    0.0782  0.3400  144.844   \n",
       "38957      0.0344      0.90100         0.748000    0.1120  0.0720   79.476   \n",
       "\n",
       "       duration_ms  time_signature  \\\n",
       "0           297787               4   \n",
       "1           441133               4   \n",
       "2           204960               4   \n",
       "3           298360               4   \n",
       "4           186067               4   \n",
       "...            ...             ...   \n",
       "38953       194493               4   \n",
       "38954       461480               4   \n",
       "38955       258373               4   \n",
       "38956       324000               3   \n",
       "38957       516280               4   \n",
       "\n",
       "                                        processed_lyrics  \\\n",
       "0      sometimes feel tire yo leave yo leave feel wea...   \n",
       "1      st anger round neck st anger round neck never ...   \n",
       "2      rick ross legendary runner know verse rick ros...   \n",
       "3      road runner road runner go hundred mile per ho...   \n",
       "4      need forgiveness need hate need acceptance nee...   \n",
       "...                                                  ...   \n",
       "38953  give get go take nothing soul roll dust roll s...   \n",
       "38954  verse say tear star apart show replace sky ver...   \n",
       "38955  hey bride mine love find another would make lo...   \n",
       "38956  desperate day solution sell price high exit st...   \n",
       "38957  child child oh child child child tremble forev...   \n",
       "\n",
       "                                            clean_lyrics  \n",
       "0      sometimes feel tire yo leave yo leave feel wea...  \n",
       "1      st anger round neck st anger round neck never ...  \n",
       "2      rick ross legendary runner know verse rick ros...  \n",
       "3      road runner road runner go hundred mile per ho...  \n",
       "4      need forgiveness need hate need acceptance nee...  \n",
       "...                                                  ...  \n",
       "38953  give get go take nothing soul roll dust roll s...  \n",
       "38954  verse say tear star apart show replace sky ver...  \n",
       "38955  hey bride mine love find another would make lo...  \n",
       "38956  desperate day solution sell price high exit st...  \n",
       "38957  child child oh child child child tremble forev...  \n",
       "\n",
       "[38958 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "#howe many unique seeds are there in df\n",
    "indices = df.index.tolist()\n",
    "seeds = []\n",
    "for i in indices:\n",
    "    seed = df['seeds'][i]\n",
    "    seed_list = seed.split(',')\n",
    "    for s in seed_list:\n",
    "        #remove '[' and ']'\n",
    "        s = s.replace('[', '')\n",
    "        s = s.replace(']', '')\n",
    "        #remove whitespace\n",
    "        s = s.strip()\n",
    "        #get rid of \"'\"\n",
    "        s = s.replace(\"'\", '')\n",
    "        seeds.append(s)\n",
    "\n",
    "seeds = list(set(seeds))\n",
    "print(len(seeds))\n",
    "\n",
    "seeds_to_index = {}\n",
    "index_to_seeds = {}\n",
    "for i in range(len(seeds)):\n",
    "    seeds_to_index[seeds[i]] = i\n",
    "    index_to_seeds[i] = seeds[i]\n",
    "\n",
    "#create one hot encoding for seeds\n",
    "seeds_encoded = []\n",
    "for i in indices:\n",
    "    encoding = np.zeros(len(seeds))\n",
    "    seed = df['seeds'][i]\n",
    "    seed_list = seed.split(',')\n",
    "    for s in seed_list:\n",
    "        #remove '[' and ']'\n",
    "        s = s.replace('[', '')\n",
    "        s = s.replace(']', '')\n",
    "        #remove whitespace\n",
    "        s = s.strip()\n",
    "        #get rid of \"'\"\n",
    "        s = s.replace(\"'\", '')\n",
    "        encoding[seeds_to_index[s]] = 1\n",
    "    seeds_encoded.append(encoding)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'carefree',\n",
       " 1: 'spiritual',\n",
       " 2: 'happy',\n",
       " 3: 'swaggering',\n",
       " 4: 'feral',\n",
       " 5: 'outrageous',\n",
       " 6: 'erotic',\n",
       " 7: 'difficult',\n",
       " 8: 'eerie',\n",
       " 9: 'sophisticated',\n",
       " 10: 'greasy',\n",
       " 11: 'celebratory',\n",
       " 12: 'quirky',\n",
       " 13: 'lush',\n",
       " 14: 'malevolent',\n",
       " 15: 'circular',\n",
       " 16: 'epic',\n",
       " 17: 'fun',\n",
       " 18: 'humorous',\n",
       " 19: 'brooding',\n",
       " 20: 'cynical',\n",
       " 21: 'nihilistic',\n",
       " 22: 'street-smart',\n",
       " 23: 'elegant',\n",
       " 24: 'refined',\n",
       " 25: 'ironic',\n",
       " 26: 'slick',\n",
       " 27: 'philosophical',\n",
       " 28: 'macabre',\n",
       " 29: 'reflective',\n",
       " 30: 'crunchy',\n",
       " 31: 'sparkling',\n",
       " 32: 'romantic',\n",
       " 33: 'languid',\n",
       " 34: 'comic',\n",
       " 35: 'poignant',\n",
       " 36: 'child-like',\n",
       " 37: 'volatile',\n",
       " 38: 'defiant',\n",
       " 39: 'calm',\n",
       " 40: 'melancholy',\n",
       " 41: 'theatrical',\n",
       " 42: 'hypnotic',\n",
       " 43: 'silly',\n",
       " 44: 'paranoid',\n",
       " 45: 'plaintive',\n",
       " 46: 'pure',\n",
       " 47: 'brash',\n",
       " 48: 'gutsy',\n",
       " 49: 'spicy',\n",
       " 50: 'searching',\n",
       " 51: 'bombastic',\n",
       " 52: 'brassy',\n",
       " 53: 'fractured',\n",
       " 54: 'strong',\n",
       " 55: 'boisterous',\n",
       " 56: 'mighty',\n",
       " 57: 'ethereal',\n",
       " 58: 'powerful',\n",
       " 59: 'reassuring',\n",
       " 60: 'visceral',\n",
       " 61: 'shimmering',\n",
       " 62: 'sentimental',\n",
       " 63: 'rousing',\n",
       " 64: 'light',\n",
       " 65: 'exciting',\n",
       " 66: 'sprawling',\n",
       " 67: 'dramatic',\n",
       " 68: 'snide',\n",
       " 69: 'sparse',\n",
       " 70: 'mechanical',\n",
       " 71: 'smooth',\n",
       " 72: 'whimsical',\n",
       " 73: 'wistful',\n",
       " 74: 'euphoric',\n",
       " 75: 'dark',\n",
       " 76: 'sensual',\n",
       " 77: 'passionate',\n",
       " 78: 'enigmatic',\n",
       " 79: 'acerbic',\n",
       " 80: 'sad',\n",
       " 81: 'spacey',\n",
       " 82: 'apocalyptic',\n",
       " 83: 'bittersweet',\n",
       " 84: 'flowing',\n",
       " 85: 'spooky',\n",
       " 86: 'naive',\n",
       " 87: 'savage',\n",
       " 88: 'negative',\n",
       " 89: 'summery',\n",
       " 90: 'insular',\n",
       " 91: 'rollicking',\n",
       " 92: 'springlike',\n",
       " 93: 'weary',\n",
       " 94: 'detached',\n",
       " 95: 'lazy',\n",
       " 96: 'exuberant',\n",
       " 97: 'rustic',\n",
       " 98: 'sugary',\n",
       " 99: 'kinetic',\n",
       " 100: 'satirical',\n",
       " 101: 'athletic',\n",
       " 102: 'demonic',\n",
       " 103: 'somber',\n",
       " 104: 'tragic',\n",
       " 105: 'suffocating',\n",
       " 106: 'cheerful',\n",
       " 107: 'gleeful',\n",
       " 108: 'ecstatic',\n",
       " 109: 'flashy',\n",
       " 110: 'threatening',\n",
       " 111: 'freewheeling',\n",
       " 112: 'positive',\n",
       " 113: 'rambunctious',\n",
       " 114: 'provocative',\n",
       " 115: 'meditative',\n",
       " 116: 'hedonistic',\n",
       " 117: 'airy',\n",
       " 118: 'cerebral',\n",
       " 119: 'reserved',\n",
       " 120: 'cathartic',\n",
       " 121: 'outraged',\n",
       " 122: 'ominous',\n",
       " 123: 'urgent',\n",
       " 124: 'playful',\n",
       " 125: 'amiable',\n",
       " 126: 'stately',\n",
       " 127: 'relaxed',\n",
       " 128: 'atmospheric',\n",
       " 129: 'reverent',\n",
       " 130: 'funereal',\n",
       " 131: 'complex',\n",
       " 132: 'sexual',\n",
       " 133: 'confident',\n",
       " 134: 'resolute',\n",
       " 135: 'laid-back',\n",
       " 136: 'elegiac',\n",
       " 137: 'peaceful',\n",
       " 138: 'uncompromising',\n",
       " 139: 'transparent',\n",
       " 140: 'energetic',\n",
       " 141: 'eccentric',\n",
       " 142: 'thuggish',\n",
       " 143: 'dreamy',\n",
       " 144: 'narcotic',\n",
       " 145: 'yearning',\n",
       " 146: 'elaborate',\n",
       " 147: 'self-conscious',\n",
       " 148: 'triumphant',\n",
       " 149: 'menacing',\n",
       " 150: 'sleazy',\n",
       " 151: 'raucous',\n",
       " 152: 'grim',\n",
       " 153: 'earnest',\n",
       " 154: 'campy',\n",
       " 155: 'nervous',\n",
       " 156: 'desperate',\n",
       " 157: 'fiery',\n",
       " 158: 'scary music',\n",
       " 159: 'precious',\n",
       " 160: 'aggressive',\n",
       " 161: 'messy',\n",
       " 162: 'manic',\n",
       " 163: 'lonely',\n",
       " 164: 'sardonic',\n",
       " 165: 'mystical',\n",
       " 166: 'intense',\n",
       " 167: 'bleak',\n",
       " 168: 'irreverent',\n",
       " 169: 'autumnal',\n",
       " 170: 'bravado',\n",
       " 171: 'angry',\n",
       " 172: 'sexy',\n",
       " 173: 'lively',\n",
       " 174: 'sweet',\n",
       " 175: 'halloween',\n",
       " 176: 'innocent',\n",
       " 177: 'effervescent',\n",
       " 178: 'harsh',\n",
       " 179: 'perky',\n",
       " 180: 'exotic',\n",
       " 181: 'nostalgic',\n",
       " 182: 'jittery',\n",
       " 183: 'agreeable',\n",
       " 184: 'cold',\n",
       " 185: 'explosive',\n",
       " 186: 'ornate',\n",
       " 187: 'serious',\n",
       " 188: 'soothing',\n",
       " 189: 'ambitious',\n",
       " 190: 'stylish',\n",
       " 191: 'monumental',\n",
       " 192: 'suspenseful',\n",
       " 193: 'bright',\n",
       " 194: 'marching',\n",
       " 195: 'mysterious',\n",
       " 196: 'pastoral',\n",
       " 197: 'nocturnal',\n",
       " 198: 'feverish',\n",
       " 199: 'restrained',\n",
       " 200: 'martial',\n",
       " 201: 'intimate',\n",
       " 202: 'tense',\n",
       " 203: 'organic',\n",
       " 204: 'hyper',\n",
       " 205: 'austere',\n",
       " 206: 'thoughtful',\n",
       " 207: 'soft',\n",
       " 208: 'brittle',\n",
       " 209: 'giddy',\n",
       " 210: 'animated',\n",
       " 211: 'quiet',\n",
       " 212: 'fierce',\n",
       " 213: 'knotty',\n",
       " 214: 'understated',\n",
       " 215: 'uplifting',\n",
       " 216: 'wry',\n",
       " 217: 'jovial',\n",
       " 218: 'regretful',\n",
       " 219: 'meandering',\n",
       " 220: 'bitter',\n",
       " 221: 'druggy',\n",
       " 222: 'witty',\n",
       " 223: 'sarcastic',\n",
       " 224: 'warm',\n",
       " 225: 'good-natured',\n",
       " 226: 'rowdy',\n",
       " 227: 'mellow',\n",
       " 228: 'driving',\n",
       " 229: 'indulgent',\n",
       " 230: 'anxious',\n",
       " 231: 'scary',\n",
       " 232: 'unsettling',\n",
       " 233: 'distraught',\n",
       " 234: 'technical',\n",
       " 235: 'rebellious',\n",
       " 236: 'angst-ridden',\n",
       " 237: 'gritty',\n",
       " 238: 'confrontational',\n",
       " 239: 'gloomy',\n",
       " 240: 'gentle',\n",
       " 241: 'lyrical',\n",
       " 242: 'clinical',\n",
       " 243: 'narrative',\n",
       " 244: 'graceful',\n",
       " 245: 'noble',\n",
       " 246: 'wintry',\n",
       " 247: 'consoling',\n",
       " 248: 'introspective',\n",
       " 249: 'joyous',\n",
       " 250: 'devotional',\n",
       " 251: 'thrilling',\n",
       " 252: 'earthy',\n",
       " 253: 'reckless',\n",
       " 254: 'optimistic',\n",
       " 255: 'ramshackle',\n",
       " 256: 'literate',\n",
       " 257: 'trippy',\n",
       " 258: 'delicate',\n",
       " 259: 'trashy',\n",
       " 260: 'sacred',\n",
       " 261: 'tender',\n",
       " 262: 'hostile',\n",
       " 263: 'hungry'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds_to_index\n",
    "index_to_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carefree</th>\n",
       "      <th>spiritual</th>\n",
       "      <th>happy</th>\n",
       "      <th>swaggering</th>\n",
       "      <th>feral</th>\n",
       "      <th>outrageous</th>\n",
       "      <th>erotic</th>\n",
       "      <th>difficult</th>\n",
       "      <th>eerie</th>\n",
       "      <th>sophisticated</th>\n",
       "      <th>...</th>\n",
       "      <th>optimistic</th>\n",
       "      <th>ramshackle</th>\n",
       "      <th>literate</th>\n",
       "      <th>trippy</th>\n",
       "      <th>delicate</th>\n",
       "      <th>trashy</th>\n",
       "      <th>sacred</th>\n",
       "      <th>tender</th>\n",
       "      <th>hostile</th>\n",
       "      <th>hungry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38953</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38955</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38958 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carefree  spiritual  happy  swaggering  feral  outrageous  erotic  \\\n",
       "0           0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "1           0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "2           0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "3           0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "4           0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "...         ...        ...    ...         ...    ...         ...     ...   \n",
       "38953       0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "38954       0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "38955       0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "38956       0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "38957       0.0        0.0    0.0         0.0    0.0         0.0     0.0   \n",
       "\n",
       "       difficult  eerie  sophisticated  ...  optimistic  ramshackle  literate  \\\n",
       "0            0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "1            0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "2            0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "3            0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "4            0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "...          ...    ...            ...  ...         ...         ...       ...   \n",
       "38953        0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "38954        0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "38955        0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "38956        0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "38957        0.0    0.0            0.0  ...         0.0         0.0       0.0   \n",
       "\n",
       "       trippy  delicate  trashy  sacred  tender  hostile  hungry  \n",
       "0         0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "1         0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "2         0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "3         0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "4         0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "...       ...       ...     ...     ...     ...      ...     ...  \n",
       "38953     0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "38954     0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "38955     0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "38956     0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "38957     0.0       0.0     0.0     0.0     0.0      0.0     0.0  \n",
       "\n",
       "[38958 rows x 264 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = pd.DataFrame(seeds_encoded, columns=seeds)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nidhi\\Documents\\UT_Austin\\Junior\\DSP\\Project\\create_dataframes.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     df_tfidf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(denselist, columns\u001b[39m=\u001b[39mfeature_names)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df_tfidf\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m x_tfidf_unigram \u001b[39m=\u001b[39m tfidf(df, (\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m), \u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\nidhi\\Documents\\UT_Austin\\Junior\\DSP\\Project\\create_dataframes.ipynb Cell 9\u001b[0m in \u001b[0;36mtfidf\u001b[1;34m(df, ngram_range, max_features)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mclean_lyrics\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m feature_names \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mget_feature_names()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m denselist \u001b[39m=\u001b[39m tfidf_matrix\u001b[39m.\u001b[39;49mtodense()\u001b[39m.\u001b[39;49mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df_tfidf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(denselist, columns\u001b[39m=\u001b[39mfeature_names)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df_tfidf\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:284\u001b[0m, in \u001b[0;36mmatrix.tolist\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtolist\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    265\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m    Return the matrix as a (possibly nested) list.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \n\u001b[0;32m    283\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__array__()\u001b[39m.\u001b[39;49mtolist()\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "def tfidf(df, ngram_range, max_features):\n",
    "    if(max_features == 0):\n",
    "        tfidf = TfidfVectorizer(ngram_range=ngram_range)\n",
    "    else:\n",
    "        tfidf = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "    tfidf_matrix = tfidf.fit_transform(df['clean_lyrics'])\n",
    "    feature_names = tfidf.get_feature_names()\n",
    "    denselist = tfidf_matrix.todense().tolist()\n",
    "    df_tfidf = pd.DataFrame(denselist, columns=feature_names)\n",
    "    return df_tfidf\n",
    "\n",
    "\n",
    "x_tfidf_unigram = tfidf(df, (1,1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nidhi\\Documents\\UT_Austin\\Junior\\DSP\\Project\\create_dataframes.ipynb Cell 10\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# audio_features = ['valence_tags', 'arousal_tags', 'dominance_tags', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# x_audio_features = df[audio_features]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# x_genre_dummies = pd.get_dummies(df['genre'])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# #save to csv\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# x_unigram_features.to_csv('x_unigram_features.csv')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_data\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39my_labels_2.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nidhi/Documents/UT_Austin/Junior/DSP/Project/create_dataframes.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mspotify_and_clean_lyrics_2.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3721\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3710\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3712\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3713\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3714\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3718\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3719\u001b[0m )\n\u001b[1;32m-> 3721\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3722\u001b[0m     path_or_buf,\n\u001b[0;32m   3723\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3724\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3725\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3726\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3727\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3728\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3729\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3730\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3731\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3732\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3733\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3734\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3735\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3736\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3737\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3738\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1191\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:311\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    308\u001b[0m slicer \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(start_i, end_i)\n\u001b[0;32m    309\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc[slicer]\n\u001b[1;32m--> 311\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mto_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[0;32m    312\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:500\u001b[0m, in \u001b[0;36mBaseBlockManager.to_native_types\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_native_types\u001b[39m(\u001b[39mself\u001b[39m: T, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    496\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m    in formatting (repr / csv).\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39m\"\u001b[39m\u001b[39mto_native_types\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py:348\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    347\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    349\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:542\u001b[0m, in \u001b[0;36mBlock.to_native_types\u001b[1;34m(self, na_rep, quoting, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    540\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_native_types\u001b[39m(\u001b[39mself\u001b[39m, na_rep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnan\u001b[39m\u001b[39m\"\u001b[39m, quoting\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Block:\n\u001b[0;32m    541\u001b[0m     \u001b[39m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[1;32m--> 542\u001b[0m     result \u001b[39m=\u001b[39m to_native_types(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues, na_rep\u001b[39m=\u001b[39mna_rep, quoting\u001b[39m=\u001b[39mquoting, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    543\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(result)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2324\u001b[0m, in \u001b[0;36mto_native_types\u001b[1;34m(values, na_rep, quoting, float_format, decimal, **kwargs)\u001b[0m\n\u001b[0;32m   2321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2322\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(values, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2324\u001b[0m values[mask] \u001b[39m=\u001b[39m na_rep\n\u001b[0;32m   2325\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2326\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "audio_features = ['valence_tags', 'arousal_tags', 'dominance_tags', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "x_audio_features = df[audio_features]\n",
    "x_genre_dummies = pd.get_dummies(df['genre'])\n",
    "\n",
    "x_unigram_features = pd.concat([x_tfidf_unigram, x_audio_features, x_genre_dummies], axis=1)\n",
    "#save to csv\n",
    "x_unigram_features.to_csv('x_unigram_features_2.csv')\n",
    "# y_data.to_csv('y_labels_2.csv')\n",
    "\n",
    "# df.to_csv('spotify_and_clean_lyrics_2.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
